{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "#keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "audio_dataset_path = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\\\\wav_dataset\"\n",
    "test_file_on = audio_dataset_path+\"\\\\\"+\"on\"+\"\\\\\"+\"3cc595de_nohash_1.wav\"\n",
    "test_file_down = audio_dataset_path+\"\\\\\"+\"down\"+\"\\\\\"+\"b87bdb22_nohash_1.wav\"\n",
    "test_file_right = audio_dataset_path+\"\\\\\"+\"right\"+\"\\\\\"+\"2aca1e72_nohash_1.wav\"\n",
    "class_label = [\"down\",\"go\",\"left\",\"on\",\"right\",\"stop\",\"up\"]\n",
    "wav_sample_rate = 16000\n",
    "num_mfcc = 40\n",
    "num_files = 2000\n",
    "num_epochs = 100\n",
    "num_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc = num_mfcc)\n",
    "        scaled = np.mean(mfcc.T, axis=0)\n",
    "    except Except as e:\n",
    "        print(\"Error with file: \", file_name)\n",
    "        return None, None\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectro_bot(dataset_path):\n",
    "    entries = []\n",
    "    start_time = time.time()\n",
    "    for dir_name in class_label:\n",
    "        print(dir_name)\n",
    "        label_index = class_label.index(dir_name)\n",
    "        dir_path = dataset_path+\"\\\\\"+dir_name\n",
    "        i = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = dir_path+\"\\\\\"+file_name\n",
    "            data = get_spectrogram(file_path)\n",
    "            entries.append([data, label_index])\n",
    "            i=i+1\n",
    "            if (i==num_files):\n",
    "                break\n",
    "    entries_data_frame = pd.DataFrame(entries, columns=[\"entries\", \"label\"])\n",
    "    entries_data_frame = entries_data_frame.sample(frac=1).reset_index(drop=True)\n",
    "    finish_time = time.time()\n",
    "    print(\"Finished processing {} files in {} seconds\".\n",
    "          format(len(entries_data_frame), finish_time-start_time))\n",
    "    return entries_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "go\n",
      "left\n",
      "on\n",
      "right\n",
      "stop\n",
      "up\n",
      "Finished processing 14000 files in 203.51063895225525 seconds\n"
     ]
    }
   ],
   "source": [
    "data_frame = spectro_bot(audio_dataset_path)\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(data_frame.entries.tolist())\n",
    "y = np.array(data_frame.label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "#=====================MODEL===========================\n",
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(256, input_shape=(num_mfcc,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#second layer\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#output layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "#===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1799      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 78,087\n",
      "Trainable params: 78,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 14.2286%\n"
     ]
    }
   ],
   "source": [
    "#compile\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10500 samples, validate on 3500 samples\n",
      "Epoch 1/100\n",
      "10500/10500 [==============================] - 1s 89us/step - loss: 8.0446 - accuracy: 0.1548 - val_loss: 1.9460 - val_accuracy: 0.1446\n",
      "Epoch 2/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 2.0001 - accuracy: 0.1398 - val_loss: 1.9461 - val_accuracy: 0.1383\n",
      "Epoch 3/100\n",
      "10500/10500 [==============================] - 1s 71us/step - loss: 1.9632 - accuracy: 0.1417 - val_loss: 1.9462 - val_accuracy: 0.1383\n",
      "Epoch 4/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9541 - accuracy: 0.1442 - val_loss: 1.9467 - val_accuracy: 0.1383\n",
      "Epoch 5/100\n",
      "10500/10500 [==============================] - 1s 89us/step - loss: 1.9498 - accuracy: 0.1435 - val_loss: 1.9467 - val_accuracy: 0.1386\n",
      "Epoch 6/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9523 - accuracy: 0.1427 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 7/100\n",
      "10500/10500 [==============================] - 1s 100us/step - loss: 1.9490 - accuracy: 0.1390 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 8/100\n",
      "10500/10500 [==============================] - 1s 83us/step - loss: 1.9478 - accuracy: 0.1422 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 9/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9498 - accuracy: 0.1449 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 10/100\n",
      "10500/10500 [==============================] - ETA: 0s - loss: 1.9479 - accuracy: 0.14 - 1s 76us/step - loss: 1.9479 - accuracy: 0.1434 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 11/100\n",
      "10500/10500 [==============================] - 1s 86us/step - loss: 1.9486 - accuracy: 0.1427 - val_loss: 1.9463 - val_accuracy: 0.1380\n",
      "Epoch 12/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9474 - accuracy: 0.1417 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 13/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9471 - accuracy: 0.1405 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 14/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9496 - accuracy: 0.1390 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 15/100\n",
      "10500/10500 [==============================] - 1s 78us/step - loss: 1.9471 - accuracy: 0.1444 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 16/100\n",
      "10500/10500 [==============================] - 1s 78us/step - loss: 1.9474 - accuracy: 0.1372 - val_loss: 1.9460 - val_accuracy: 0.1380\n",
      "Epoch 17/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9467 - accuracy: 0.1414 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 18/100\n",
      "10500/10500 [==============================] - 1s 84us/step - loss: 1.9463 - accuracy: 0.1430 - val_loss: 1.9461 - val_accuracy: 0.1426\n",
      "Epoch 19/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9478 - accuracy: 0.1354 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 20/100\n",
      "10500/10500 [==============================] - 1s 105us/step - loss: 1.9467 - accuracy: 0.1393 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 21/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9466 - accuracy: 0.1398 - val_loss: 1.9463 - val_accuracy: 0.1386\n",
      "Epoch 22/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9470 - accuracy: 0.1408 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 23/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9471 - accuracy: 0.1431 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 24/100\n",
      "10500/10500 [==============================] - 1s 92us/step - loss: 1.9468 - accuracy: 0.1449 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 25/100\n",
      "10500/10500 [==============================] - 1s 72us/step - loss: 1.9479 - accuracy: 0.1419 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 26/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9481 - accuracy: 0.1420 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 27/100\n",
      "10500/10500 [==============================] - 1s 74us/step - loss: 1.9473 - accuracy: 0.1441 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 28/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9464 - accuracy: 0.1415 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 29/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9467 - accuracy: 0.1427 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 30/100\n",
      "10500/10500 [==============================] - 1s 81us/step - loss: 1.9468 - accuracy: 0.1410 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 31/100\n",
      "10500/10500 [==============================] - 1s 95us/step - loss: 1.9476 - accuracy: 0.1439 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 32/100\n",
      "10500/10500 [==============================] - 2s 146us/step - loss: 1.9481 - accuracy: 0.1425 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 33/100\n",
      "10500/10500 [==============================] - 1s 110us/step - loss: 1.9465 - accuracy: 0.1448 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 34/100\n",
      "10500/10500 [==============================] - 1s 107us/step - loss: 1.9480 - accuracy: 0.1388 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 35/100\n",
      "10500/10500 [==============================] - 1s 110us/step - loss: 1.9482 - accuracy: 0.1419 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 36/100\n",
      "10500/10500 [==============================] - 1s 100us/step - loss: 1.9460 - accuracy: 0.1377 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 37/100\n",
      "10500/10500 [==============================] - 1s 99us/step - loss: 1.9464 - accuracy: 0.1413 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 38/100\n",
      "10500/10500 [==============================] - 1s 105us/step - loss: 1.9467 - accuracy: 0.1420 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 39/100\n",
      "10500/10500 [==============================] - 1s 94us/step - loss: 1.9462 - accuracy: 0.1388 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 40/100\n",
      "10500/10500 [==============================] - 1s 80us/step - loss: 1.9465 - accuracy: 0.1416 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 41/100\n",
      "10500/10500 [==============================] - 1s 83us/step - loss: 1.9461 - accuracy: 0.1409 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 42/100\n",
      "10500/10500 [==============================] - 1s 87us/step - loss: 1.9462 - accuracy: 0.1425 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 43/100\n",
      "10500/10500 [==============================] - 1s 70us/step - loss: 1.9467 - accuracy: 0.1429 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 44/100\n",
      "10500/10500 [==============================] - 1s 72us/step - loss: 1.9460 - accuracy: 0.1421 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 45/100\n",
      "10500/10500 [==============================] - 1s 74us/step - loss: 1.9467 - accuracy: 0.1413 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 46/100\n",
      "10500/10500 [==============================] - 1s 72us/step - loss: 1.9462 - accuracy: 0.1426 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 47/100\n",
      "10500/10500 [==============================] - 1s 91us/step - loss: 1.9471 - accuracy: 0.1428 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 48/100\n",
      "10500/10500 [==============================] - 1s 83us/step - loss: 1.9472 - accuracy: 0.1416 - val_loss: 1.9460 - val_accuracy: 0.1380\n",
      "Epoch 49/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9492 - accuracy: 0.1354 - val_loss: 1.9460 - val_accuracy: 0.1380\n",
      "Epoch 50/100\n",
      "10500/10500 [==============================] - 1s 74us/step - loss: 1.9476 - accuracy: 0.1415 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 51/100\n",
      "10500/10500 [==============================] - 1s 71us/step - loss: 1.9479 - accuracy: 0.1383 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 52/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9465 - accuracy: 0.1434 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 53/100\n",
      "10500/10500 [==============================] - 1s 74us/step - loss: 1.9461 - accuracy: 0.1404 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 54/100\n",
      "10500/10500 [==============================] - 1s 83us/step - loss: 1.9464 - accuracy: 0.1410 - val_loss: 1.9461 - val_accuracy: 0.1426\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9486 - accuracy: 0.1429 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 56/100\n",
      "10500/10500 [==============================] - 1s 71us/step - loss: 1.9461 - accuracy: 0.1400 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 57/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9463 - accuracy: 0.1416 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 58/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9468 - accuracy: 0.1384 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 59/100\n",
      "10500/10500 [==============================] - 1s 70us/step - loss: 1.9462 - accuracy: 0.1446 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 60/100\n",
      "10500/10500 [==============================] - 1s 70us/step - loss: 1.9463 - accuracy: 0.1384 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 61/100\n",
      "10500/10500 [==============================] - 1s 89us/step - loss: 1.9464 - accuracy: 0.1393 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 62/100\n",
      "10500/10500 [==============================] - 1s 89us/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 63/100\n",
      "10500/10500 [==============================] - 1s 82us/step - loss: 1.9459 - accuracy: 0.1358 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 64/100\n",
      "10500/10500 [==============================] - 1s 78us/step - loss: 1.9464 - accuracy: 0.1393 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 65/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9468 - accuracy: 0.1395 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 66/100\n",
      "10500/10500 [==============================] - 1s 72us/step - loss: 1.9461 - accuracy: 0.1382 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 67/100\n",
      "10500/10500 [==============================] - 1s 82us/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 68/100\n",
      "10500/10500 [==============================] - 1s 95us/step - loss: 1.9459 - accuracy: 0.1434 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 69/100\n",
      "10500/10500 [==============================] - 1s 84us/step - loss: 1.9461 - accuracy: 0.1435 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 70/100\n",
      "10500/10500 [==============================] - 1s 81us/step - loss: 1.9476 - accuracy: 0.1395 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 71/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9461 - accuracy: 0.1430 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 72/100\n",
      "10500/10500 [==============================] - 1s 74us/step - loss: 1.9475 - accuracy: 0.1374 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 73/100\n",
      "10500/10500 [==============================] - 1s 80us/step - loss: 1.9465 - accuracy: 0.1430 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 74/100\n",
      "10500/10500 [==============================] - 1s 97us/step - loss: 1.9461 - accuracy: 0.1418 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 75/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9461 - accuracy: 0.1377 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 76/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 77/100\n",
      "10500/10500 [==============================] - 1s 81us/step - loss: 1.9469 - accuracy: 0.1370 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 78/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9461 - accuracy: 0.1424 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 79/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9481 - accuracy: 0.1378 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 80/100\n",
      "10500/10500 [==============================] - 1s 112us/step - loss: 1.9461 - accuracy: 0.1414 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 81/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9462 - accuracy: 0.1423 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 82/100\n",
      "10500/10500 [==============================] - 1s 74us/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 83/100\n",
      "10500/10500 [==============================] - 1s 80us/step - loss: 1.9474 - accuracy: 0.1386 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 84/100\n",
      "10500/10500 [==============================] - 1s 80us/step - loss: 1.9468 - accuracy: 0.1413 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 85/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9461 - accuracy: 0.1396 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 86/100\n",
      "10500/10500 [==============================] - 1s 82us/step - loss: 1.9461 - accuracy: 0.1382 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 87/100\n",
      "10500/10500 [==============================] - 1s 85us/step - loss: 1.9462 - accuracy: 0.1349 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 88/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9465 - accuracy: 0.1407 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 89/100\n",
      "10500/10500 [==============================] - 1s 79us/step - loss: 1.9466 - accuracy: 0.1386 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 90/100\n",
      "10500/10500 [==============================] - 1s 78us/step - loss: 1.9464 - accuracy: 0.1387 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 91/100\n",
      "10500/10500 [==============================] - 1s 73us/step - loss: 1.9461 - accuracy: 0.1424 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 92/100\n",
      "10500/10500 [==============================] - 1s 106us/step - loss: 1.9462 - accuracy: 0.1418 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Epoch 93/100\n",
      "10500/10500 [==============================] - 1s 92us/step - loss: 1.9466 - accuracy: 0.1430 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 94/100\n",
      "10500/10500 [==============================] - 1s 75us/step - loss: 1.9461 - accuracy: 0.1404 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 95/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9461 - accuracy: 0.1410 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 96/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9461 - accuracy: 0.1422 - val_loss: 1.9461 - val_accuracy: 0.1380\n",
      "Epoch 97/100\n",
      "10500/10500 [==============================] - 1s 76us/step - loss: 1.9462 - accuracy: 0.1371 - val_loss: 1.9462 - val_accuracy: 0.1380\n",
      "Epoch 98/100\n",
      "10500/10500 [==============================] - 1s 77us/step - loss: 1.9465 - accuracy: 0.1413 - val_loss: 1.9462 - val_accuracy: 0.1386\n",
      "Epoch 99/100\n",
      "10500/10500 [==============================] - 1s 86us/step - loss: 1.9462 - accuracy: 0.1402 - val_loss: 1.9461 - val_accuracy: 0.1426\n",
      "Epoch 100/100\n",
      "10500/10500 [==============================] - 1s 78us/step - loss: 1.9481 - accuracy: 0.1379 - val_loss: 1.9461 - val_accuracy: 0.1386\n",
      "Training finished in 86.83766770362854 seconds\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=num_batch, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(x_test, y_test), \n",
    "          verbose=1)\n",
    "finish_time = time.time()\n",
    "print(\"Training finished in {} seconds\".format(finish_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.14428570866584778\n",
      "Testing Accuracy:  0.13857142627239227\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name,model):\n",
    "    prediction_feature = extract_feature(file_name)\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", class_label[predicted_class[0]], '\\n') \n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: stop \n",
      "\n",
      "0 \t\t :  0.14084726572036743164062500000000\n",
      "1 \t\t :  0.14408060908317565917968750000000\n",
      "2 \t\t :  0.14361627399921417236328125000000\n",
      "3 \t\t :  0.14359337091445922851562500000000\n",
      "4 \t\t :  0.14173272252082824707031250000000\n",
      "5 \t\t :  0.14410583674907684326171875000000\n",
      "6 \t\t :  0.14202395081520080566406250000000\n"
     ]
    }
   ],
   "source": [
    "print_prediction(test_file_on, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
