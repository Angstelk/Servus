{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "#keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "audio_dataset_path = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\\\\wav_dataset\"\n",
    "test_file_on = audio_dataset_path+\"\\\\\"+\"on\"+\"\\\\\"+\"3cc595de_nohash_1.wav\"\n",
    "test_file_down = audio_dataset_path+\"\\\\\"+\"down\"+\"\\\\\"+\"b87bdb22_nohash_1.wav\"\n",
    "test_file_right = audio_dataset_path+\"\\\\\"+\"right\"+\"\\\\\"+\"2aca1e72_nohash_1.wav\"\n",
    "class_label = [\"down\",\"go\",\"left\",\"on\",\"right\",\"stop\",\"up\"]\n",
    "wav_sample_rate = 16000\n",
    "num_mfcc = 40\n",
    "num_files = 1\n",
    "num_epochs = 20\n",
    "num_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc = num_mfcc)\n",
    "        scaled = np.mean(mfcc.T, axis=0)\n",
    "    except:\n",
    "        print(\"Error with file: \", file_name)\n",
    "        return None, None\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectro_bot(dataset_path):\n",
    "    entries = []\n",
    "    start_time = time.time()\n",
    "    for dir_name in class_label:\n",
    "        print(dir_name)\n",
    "        label_index = class_label.index(dir_name)\n",
    "        dir_path = dataset_path+\"\\\\\"+dir_name\n",
    "        i = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            while (i!=num_files):\n",
    "                file_path = dir_path+\"\\\\\"+file_name\n",
    "                data = get_spectrogram(file_path)\n",
    "                entries.append([data, label_index])\n",
    "                i=i+1\n",
    "    entries_data_frame = pd.DataFrame(entries, columns=[\"entries\", \"label\"])\n",
    "    entries_data_frame = entries_data_frame.sample(frac=1).reset_index(drop=True)\n",
    "    finish_time = time.time()\n",
    "    print(\"Finished processing {} files in {} seconds\".\n",
    "          format(len(entries_data_frame), finish_time-start_time))\n",
    "    return entries_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 3500 files in 49.58353400230408 seconds\n"
     ]
    }
   ],
   "source": [
    "data_frame = spectro_bot(audio_dataset_path)\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(data_frame.entries.tolist())\n",
    "y = np.array(data_frame.label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "#=====================MODEL===========================\n",
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(256, input_shape=(num_mfcc,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#second layer\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#output layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "#===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1799      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 78,087\n",
      "Trainable params: 78,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 13.8286%\n"
     ]
    }
   ],
   "source": [
    "#compile\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2625 samples, validate on 875 samples\n",
      "Epoch 1/20\n",
      "2625/2625 [==============================] - 0s 155us/step - loss: 8.8368 - accuracy: 0.4770 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "2625/2625 [==============================] - 0s 161us/step - loss: 0.7543 - accuracy: 0.8354 - val_loss: 1.8438e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "2625/2625 [==============================] - 0s 129us/step - loss: 0.2528 - accuracy: 0.9265 - val_loss: 4.1543e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "2625/2625 [==============================] - 0s 124us/step - loss: 0.1247 - accuracy: 0.9642 - val_loss: 4.5401e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "2625/2625 [==============================] - 0s 95us/step - loss: 0.0571 - accuracy: 0.9813 - val_loss: 6.5831e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "2625/2625 [==============================] - 0s 91us/step - loss: 0.0315 - accuracy: 0.9924 - val_loss: 4.7987e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "2625/2625 [==============================] - 0s 95us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 2.6485e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "2625/2625 [==============================] - 0s 97us/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 1.6826e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "2625/2625 [==============================] - 0s 93us/step - loss: 0.0203 - accuracy: 0.9954 - val_loss: 1.0177e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "2625/2625 [==============================] - 0s 87us/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 6.6485e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2625/2625 [==============================] - 0s 93us/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 6.8120e-08 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2625/2625 [==============================] - 0s 104us/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 1.6894e-08 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "2625/2625 [==============================] - 0s 93us/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 3.3924e-08 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2625/2625 [==============================] - 0s 93us/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.5327e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2625/2625 [==============================] - 0s 99us/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 3.3924e-08 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2625/2625 [==============================] - 0s 99us/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.6894e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2625/2625 [==============================] - 0s 90us/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2625/2625 [==============================] - 0s 97us/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 1.0204e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2625/2625 [==============================] - 0s 91us/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.6894e-08 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2625/2625 [==============================] - 0s 94us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Training finished in 5.99422287940979 seconds\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=num_batch, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(x_test, y_test), \n",
    "          verbose=1)\n",
    "finish_time = time.time()\n",
    "print(\"Training finished in {} seconds\".format(finish_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name,model):\n",
    "    prediction_feature = extract_feature(file_name)\n",
    "    \"\"\"\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", class_label[predicted_class[0]], '\\n') \n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )\n",
    "    \"\"\"\n",
    "    preds = model.predict(prediction_feature)\n",
    "    print(class_label[preds.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n"
     ]
    }
   ],
   "source": [
    "print_prediction(test_file_down, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
