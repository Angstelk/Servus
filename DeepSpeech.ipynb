{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "#keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Nadam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "audio_dataset_path = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\\\\wav_dataset\"\n",
    "#test files for prediction\n",
    "test_file_on = audio_dataset_path+\"\\\\\"+\"on\"+\"\\\\\"+\"3cc595de_nohash_1.wav\"\n",
    "test_file_down = audio_dataset_path+\"\\\\\"+\"down\"+\"\\\\\"+\"b87bdb22_nohash_1.wav\"\n",
    "test_file_right = audio_dataset_path+\"\\\\\"+\"right\"+\"\\\\\"+\"2aca1e72_nohash_1.wav\"\n",
    "class_label = [\"down\",\"go\",\"left\",\"on\",\"right\",\"stop\",\"up\"]\n",
    "wav_sample_rate = 16000\n",
    "num_mfcc = 40\n",
    "#number of spectograms to make (per class)\n",
    "num_files = 500\n",
    "num_epochs = 120\n",
    "num_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes mfc spectrogram out of .wav file and rescales it\n",
    "def get_spectrogram(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc = num_mfcc)\n",
    "        scaled = np.mean(mfcc.T, axis=0)\n",
    "    except Except as e:\n",
    "        print(\"Error with file: \", file_name)\n",
    "        return None, None\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterates through all of files in dataset and makes spectrograms out of them\n",
    "#saves spectrograms in numpy DataFrame (excel-like sheet)\n",
    "def spectro_bot(dataset_path):\n",
    "    entries = []\n",
    "    start_time = time.time()\n",
    "    for dir_name in class_label:\n",
    "        print(dir_name)\n",
    "        label_index = class_label.index(dir_name)\n",
    "        dir_path = dataset_path+\"\\\\\"+dir_name\n",
    "        i = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = dir_path+\"\\\\\"+file_name\n",
    "            data = get_spectrogram(file_path)\n",
    "            entries.append([data, label_index])\n",
    "            i=i+1\n",
    "            if (i==num_files):\n",
    "                break\n",
    "    entries_data_frame = pd.DataFrame(entries, columns=[\"entries\", \"label\"])\n",
    "    entries_data_frame = entries_data_frame.sample(frac=1).reset_index(drop=True)\n",
    "    finish_time = time.time()\n",
    "    print(\"Finished processing {} files in {} seconds\".\n",
    "          format(len(entries_data_frame), finish_time-start_time))\n",
    "    return entries_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "go\n",
      "left\n",
      "on\n",
      "right\n",
      "stop\n",
      "up\n",
      "Finished processing 3500 files in 41.03398537635803 seconds\n"
     ]
    }
   ],
   "source": [
    "#make spectrograms\n",
    "data_frame = spectro_bot(audio_dataset_path)\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(data_frame.entries.tolist())\n",
    "y = np.array(data_frame.label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "#split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "#=====================MODEL===========================\n",
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(300, input_shape=(num_mfcc,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#second layer\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#output layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "#===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               12300     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 4207      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 197,107\n",
      "Trainable params: 197,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 14.2857%\n"
     ]
    }
   ],
   "source": [
    "#compile\n",
    "model.compile(optimizer='Nadam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2625 samples, validate on 875 samples\n",
      "Epoch 1/120\n",
      "2625/2625 [==============================] - 1s 223us/step - loss: 12.6209 - accuracy: 0.1829 - val_loss: 2.0212 - val_accuracy: 0.1589\n",
      "Epoch 2/120\n",
      "2625/2625 [==============================] - 0s 123us/step - loss: 2.0065 - accuracy: 0.2126 - val_loss: 1.8909 - val_accuracy: 0.1989\n",
      "Epoch 3/120\n",
      "2625/2625 [==============================] - 0s 142us/step - loss: 1.9463 - accuracy: 0.2137 - val_loss: 1.9085 - val_accuracy: 0.1829\n",
      "Epoch 4/120\n",
      "2625/2625 [==============================] - 0s 174us/step - loss: 1.8588 - accuracy: 0.2598 - val_loss: 1.8831 - val_accuracy: 0.2343\n",
      "Epoch 5/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.8105 - accuracy: 0.2865 - val_loss: 1.8880 - val_accuracy: 0.2411\n",
      "Epoch 6/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.7170 - accuracy: 0.3170 - val_loss: 1.6136 - val_accuracy: 0.3783\n",
      "Epoch 7/120\n",
      "2625/2625 [==============================] - 0s 120us/step - loss: 1.6972 - accuracy: 0.3250 - val_loss: 1.7974 - val_accuracy: 0.2674\n",
      "Epoch 8/120\n",
      "2625/2625 [==============================] - 0s 128us/step - loss: 1.6583 - accuracy: 0.3630 - val_loss: 2.0563 - val_accuracy: 0.2949\n",
      "Epoch 9/120\n",
      "2625/2625 [==============================] - 0s 119us/step - loss: 1.6642 - accuracy: 0.3581 - val_loss: 1.6053 - val_accuracy: 0.3714\n",
      "Epoch 10/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.5958 - accuracy: 0.3870 - val_loss: 1.4897 - val_accuracy: 0.4251\n",
      "Epoch 11/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.5866 - accuracy: 0.3954 - val_loss: 2.3894 - val_accuracy: 0.2331\n",
      "Epoch 12/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.5627 - accuracy: 0.3985 - val_loss: 1.5516 - val_accuracy: 0.4034\n",
      "Epoch 13/120\n",
      "2625/2625 [==============================] - 0s 119us/step - loss: 1.5046 - accuracy: 0.4171 - val_loss: 1.5911 - val_accuracy: 0.4000\n",
      "Epoch 14/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.4857 - accuracy: 0.4408 - val_loss: 1.7701 - val_accuracy: 0.3417\n",
      "Epoch 15/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.4334 - accuracy: 0.4602 - val_loss: 1.5989 - val_accuracy: 0.3840\n",
      "Epoch 16/120\n",
      "2625/2625 [==============================] - 0s 152us/step - loss: 1.4305 - accuracy: 0.4705 - val_loss: 1.5569 - val_accuracy: 0.4286\n",
      "Epoch 17/120\n",
      "2625/2625 [==============================] - 0s 152us/step - loss: 1.3831 - accuracy: 0.4823 - val_loss: 1.5262 - val_accuracy: 0.4114\n",
      "Epoch 18/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.3638 - accuracy: 0.4884 - val_loss: 1.5950 - val_accuracy: 0.4354\n",
      "Epoch 19/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 1.3691 - accuracy: 0.4861 - val_loss: 1.4804 - val_accuracy: 0.4434\n",
      "Epoch 20/120\n",
      "2625/2625 [==============================] - 0s 125us/step - loss: 1.3227 - accuracy: 0.5040 - val_loss: 1.3384 - val_accuracy: 0.5109\n",
      "Epoch 21/120\n",
      "2625/2625 [==============================] - 0s 122us/step - loss: 1.3016 - accuracy: 0.5166 - val_loss: 1.8598 - val_accuracy: 0.3611\n",
      "Epoch 22/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.4180 - accuracy: 0.4815 - val_loss: 1.5244 - val_accuracy: 0.4514\n",
      "Epoch 23/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.3241 - accuracy: 0.5120 - val_loss: 1.6748 - val_accuracy: 0.3874\n",
      "Epoch 24/120\n",
      "2625/2625 [==============================] - 0s 129us/step - loss: 1.3738 - accuracy: 0.4975 - val_loss: 1.3935 - val_accuracy: 0.4834\n",
      "Epoch 25/120\n",
      "2625/2625 [==============================] - 0s 124us/step - loss: 1.2786 - accuracy: 0.5291 - val_loss: 1.5469 - val_accuracy: 0.4366\n",
      "Epoch 26/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.2977 - accuracy: 0.5250 - val_loss: 1.4986 - val_accuracy: 0.4766\n",
      "Epoch 27/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.2711 - accuracy: 0.5250 - val_loss: 1.3607 - val_accuracy: 0.5040\n",
      "Epoch 28/120\n",
      "2625/2625 [==============================] - 0s 125us/step - loss: 1.2202 - accuracy: 0.5429 - val_loss: 1.5694 - val_accuracy: 0.4126\n",
      "Epoch 29/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.2827 - accuracy: 0.5154 - val_loss: 1.3538 - val_accuracy: 0.4949\n",
      "Epoch 30/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.2145 - accuracy: 0.5356 - val_loss: 1.4810 - val_accuracy: 0.4434\n",
      "Epoch 31/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.2277 - accuracy: 0.5310 - val_loss: 1.3949 - val_accuracy: 0.4777\n",
      "Epoch 32/120\n",
      "2625/2625 [==============================] - 0s 134us/step - loss: 1.2477 - accuracy: 0.5387 - val_loss: 1.4022 - val_accuracy: 0.4903\n",
      "Epoch 33/120\n",
      "2625/2625 [==============================] - 0s 165us/step - loss: 1.1839 - accuracy: 0.5570 - val_loss: 1.3975 - val_accuracy: 0.5017\n",
      "Epoch 34/120\n",
      "2625/2625 [==============================] - 0s 189us/step - loss: 1.1492 - accuracy: 0.5661 - val_loss: 1.3484 - val_accuracy: 0.5154\n",
      "Epoch 35/120\n",
      "2625/2625 [==============================] - 0s 153us/step - loss: 1.1299 - accuracy: 0.5836 - val_loss: 2.1384 - val_accuracy: 0.3817\n",
      "Epoch 36/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.1744 - accuracy: 0.5688 - val_loss: 2.0983 - val_accuracy: 0.3680\n",
      "Epoch 37/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 1.2115 - accuracy: 0.5482 - val_loss: 1.3684 - val_accuracy: 0.4743\n",
      "Epoch 38/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.1347 - accuracy: 0.5768 - val_loss: 1.5318 - val_accuracy: 0.4891\n",
      "Epoch 39/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.1191 - accuracy: 0.5825 - val_loss: 1.2663 - val_accuracy: 0.5314\n",
      "Epoch 40/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.0861 - accuracy: 0.5989 - val_loss: 1.5359 - val_accuracy: 0.4754\n",
      "Epoch 41/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.1288 - accuracy: 0.5878 - val_loss: 1.4311 - val_accuracy: 0.4903\n",
      "Epoch 42/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.0501 - accuracy: 0.6019 - val_loss: 1.3323 - val_accuracy: 0.4971\n",
      "Epoch 43/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.0329 - accuracy: 0.6137 - val_loss: 1.4125 - val_accuracy: 0.5383\n",
      "Epoch 44/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.0175 - accuracy: 0.6175 - val_loss: 1.3113 - val_accuracy: 0.5406\n",
      "Epoch 45/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 1.0311 - accuracy: 0.6202 - val_loss: 1.3277 - val_accuracy: 0.5360\n",
      "Epoch 46/120\n",
      "2625/2625 [==============================] - 0s 124us/step - loss: 0.9612 - accuracy: 0.6430 - val_loss: 1.4048 - val_accuracy: 0.5543\n",
      "Epoch 47/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 0.9778 - accuracy: 0.6312 - val_loss: 1.3983 - val_accuracy: 0.5166\n",
      "Epoch 48/120\n",
      "2625/2625 [==============================] - 0s 134us/step - loss: 0.9812 - accuracy: 0.6278 - val_loss: 1.4420 - val_accuracy: 0.5051\n",
      "Epoch 49/120\n",
      "2625/2625 [==============================] - 0s 159us/step - loss: 0.9812 - accuracy: 0.6309 - val_loss: 1.2936 - val_accuracy: 0.5554\n",
      "Epoch 50/120\n",
      "2625/2625 [==============================] - 0s 129us/step - loss: 0.9189 - accuracy: 0.6663 - val_loss: 1.8252 - val_accuracy: 0.4789\n",
      "Epoch 51/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 1.0201 - accuracy: 0.6339 - val_loss: 1.8316 - val_accuracy: 0.4446\n",
      "Epoch 52/120\n",
      "2625/2625 [==============================] - 0s 130us/step - loss: 1.0591 - accuracy: 0.6038 - val_loss: 1.3222 - val_accuracy: 0.5326\n",
      "Epoch 53/120\n",
      "2625/2625 [==============================] - 0s 118us/step - loss: 0.9703 - accuracy: 0.6377 - val_loss: 1.3831 - val_accuracy: 0.5383\n",
      "Epoch 54/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 0.9421 - accuracy: 0.6415 - val_loss: 1.3827 - val_accuracy: 0.5371\n",
      "Epoch 55/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 0.9390 - accuracy: 0.6499 - val_loss: 1.3856 - val_accuracy: 0.5566\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - 0s 120us/step - loss: 0.9065 - accuracy: 0.6724 - val_loss: 1.2856 - val_accuracy: 0.5737\n",
      "Epoch 57/120\n",
      "2625/2625 [==============================] - 0s 125us/step - loss: 0.8607 - accuracy: 0.6853 - val_loss: 1.6696 - val_accuracy: 0.4994\n",
      "Epoch 58/120\n",
      "2625/2625 [==============================] - 0s 124us/step - loss: 0.9565 - accuracy: 0.6598 - val_loss: 1.4199 - val_accuracy: 0.5143\n",
      "Epoch 59/120\n",
      "2625/2625 [==============================] - 0s 122us/step - loss: 0.8942 - accuracy: 0.6697 - val_loss: 1.4912 - val_accuracy: 0.5371\n",
      "Epoch 60/120\n",
      "2625/2625 [==============================] - 0s 115us/step - loss: 0.8683 - accuracy: 0.6815 - val_loss: 1.4652 - val_accuracy: 0.5463\n",
      "Epoch 61/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 0.8992 - accuracy: 0.6811 - val_loss: 1.3770 - val_accuracy: 0.5509\n",
      "Epoch 62/120\n",
      "2625/2625 [==============================] - 0s 123us/step - loss: 0.8543 - accuracy: 0.6811 - val_loss: 1.3511 - val_accuracy: 0.5771\n",
      "Epoch 63/120\n",
      "2625/2625 [==============================] - 0s 118us/step - loss: 0.8267 - accuracy: 0.6952 - val_loss: 1.3934 - val_accuracy: 0.5543\n",
      "Epoch 64/120\n",
      "2625/2625 [==============================] - 0s 129us/step - loss: 0.8311 - accuracy: 0.6949 - val_loss: 1.7212 - val_accuracy: 0.5097\n",
      "Epoch 65/120\n",
      "2625/2625 [==============================] - 0s 150us/step - loss: 0.9763 - accuracy: 0.6510 - val_loss: 1.5155 - val_accuracy: 0.5269\n",
      "Epoch 66/120\n",
      "2625/2625 [==============================] - 1s 191us/step - loss: 1.0223 - accuracy: 0.6316 - val_loss: 1.3675 - val_accuracy: 0.5486\n",
      "Epoch 67/120\n",
      "2625/2625 [==============================] - 0s 138us/step - loss: 0.8447 - accuracy: 0.6861 - val_loss: 1.5214 - val_accuracy: 0.5314\n",
      "Epoch 68/120\n",
      "2625/2625 [==============================] - 0s 120us/step - loss: 0.8546 - accuracy: 0.6804 - val_loss: 1.4396 - val_accuracy: 0.5600\n",
      "Epoch 69/120\n",
      "2625/2625 [==============================] - 0s 128us/step - loss: 0.8163 - accuracy: 0.6949 - val_loss: 1.5048 - val_accuracy: 0.5394\n",
      "Epoch 70/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 0.9377 - accuracy: 0.6621 - val_loss: 1.3942 - val_accuracy: 0.5577\n",
      "Epoch 71/120\n",
      "2625/2625 [==============================] - 0s 120us/step - loss: 0.8468 - accuracy: 0.6922 - val_loss: 1.8945 - val_accuracy: 0.4709\n",
      "Epoch 72/120\n",
      "2625/2625 [==============================] - 0s 120us/step - loss: 1.2179 - accuracy: 0.5859 - val_loss: 1.3948 - val_accuracy: 0.5246\n",
      "Epoch 73/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 0.9480 - accuracy: 0.6533 - val_loss: 1.4172 - val_accuracy: 0.5623\n",
      "Epoch 74/120\n",
      "2625/2625 [==============================] - 0s 124us/step - loss: 0.9107 - accuracy: 0.6792 - val_loss: 1.4014 - val_accuracy: 0.5474\n",
      "Epoch 75/120\n",
      "2625/2625 [==============================] - 0s 122us/step - loss: 0.9045 - accuracy: 0.6701 - val_loss: 1.4020 - val_accuracy: 0.5326\n",
      "Epoch 76/120\n",
      "2625/2625 [==============================] - 0s 120us/step - loss: 0.8661 - accuracy: 0.6777 - val_loss: 1.5079 - val_accuracy: 0.5029\n",
      "Epoch 77/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 0.9825 - accuracy: 0.6533 - val_loss: 1.5462 - val_accuracy: 0.4903\n",
      "Epoch 78/120\n",
      "2625/2625 [==============================] - 0s 122us/step - loss: 1.0193 - accuracy: 0.6305 - val_loss: 1.5267 - val_accuracy: 0.5131\n",
      "Epoch 79/120\n",
      "2625/2625 [==============================] - 0s 119us/step - loss: 0.8947 - accuracy: 0.6750 - val_loss: 1.4355 - val_accuracy: 0.5600\n",
      "Epoch 80/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 0.8545 - accuracy: 0.6903 - val_loss: 1.4217 - val_accuracy: 0.5463\n",
      "Epoch 81/120\n",
      "2625/2625 [==============================] - 0s 132us/step - loss: 0.8200 - accuracy: 0.6945 - val_loss: 1.3816 - val_accuracy: 0.5680\n",
      "Epoch 82/120\n",
      "2625/2625 [==============================] - 0s 158us/step - loss: 0.8654 - accuracy: 0.6815 - val_loss: 1.4339 - val_accuracy: 0.5589\n",
      "Epoch 83/120\n",
      "2625/2625 [==============================] - 0s 140us/step - loss: 0.8240 - accuracy: 0.7051 - val_loss: 1.4361 - val_accuracy: 0.5189\n",
      "Epoch 84/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 0.8513 - accuracy: 0.6922 - val_loss: 1.4154 - val_accuracy: 0.5680\n",
      "Epoch 85/120\n",
      "2625/2625 [==============================] - 0s 120us/step - loss: 0.8282 - accuracy: 0.6937 - val_loss: 1.5395 - val_accuracy: 0.5486\n",
      "Epoch 86/120\n",
      "2625/2625 [==============================] - 0s 128us/step - loss: 0.8458 - accuracy: 0.6990 - val_loss: 1.3861 - val_accuracy: 0.5589\n",
      "Epoch 87/120\n",
      "2625/2625 [==============================] - 0s 125us/step - loss: 0.8412 - accuracy: 0.6994 - val_loss: 1.4298 - val_accuracy: 0.5680\n",
      "Epoch 88/120\n",
      "2625/2625 [==============================] - 0s 122us/step - loss: 0.7948 - accuracy: 0.7166 - val_loss: 1.4200 - val_accuracy: 0.5589\n",
      "Epoch 89/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 0.7620 - accuracy: 0.7284 - val_loss: 1.4866 - val_accuracy: 0.5474\n",
      "Epoch 90/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 0.8026 - accuracy: 0.7124 - val_loss: 1.5170 - val_accuracy: 0.5451\n",
      "Epoch 91/120\n",
      "2625/2625 [==============================] - 0s 121us/step - loss: 0.7705 - accuracy: 0.7215 - val_loss: 1.5736 - val_accuracy: 0.5669\n",
      "Epoch 92/120\n",
      "2625/2625 [==============================] - 0s 126us/step - loss: 0.7780 - accuracy: 0.7093 - val_loss: 1.4060 - val_accuracy: 0.5760\n",
      "Epoch 93/120\n",
      "2625/2625 [==============================] - 0s 127us/step - loss: 0.7677 - accuracy: 0.7234 - val_loss: 1.4414 - val_accuracy: 0.5829\n",
      "Epoch 94/120\n",
      "2625/2625 [==============================] - 0s 125us/step - loss: 0.7726 - accuracy: 0.7295 - val_loss: 1.4718 - val_accuracy: 0.5486\n",
      "Epoch 95/120\n",
      "2625/2625 [==============================] - 0s 122us/step - loss: 0.7347 - accuracy: 0.7318 - val_loss: 1.4498 - val_accuracy: 0.5509\n",
      "Epoch 96/120\n",
      "2625/2625 [==============================] - 0s 152us/step - loss: 0.7378 - accuracy: 0.7330 - val_loss: 1.5107 - val_accuracy: 0.5520\n",
      "Epoch 97/120\n",
      "2625/2625 [==============================] - 1s 251us/step - loss: 0.7752 - accuracy: 0.7295 - val_loss: 1.4865 - val_accuracy: 0.5589\n",
      "Epoch 98/120\n",
      "2625/2625 [==============================] - 0s 180us/step - loss: 0.7305 - accuracy: 0.7398 - val_loss: 1.5432 - val_accuracy: 0.5474\n",
      "Epoch 99/120\n",
      "2625/2625 [==============================] - 0s 145us/step - loss: 0.7066 - accuracy: 0.7402 - val_loss: 1.4850 - val_accuracy: 0.5783\n",
      "Epoch 100/120\n",
      "2625/2625 [==============================] - 0s 154us/step - loss: 0.6859 - accuracy: 0.7535 - val_loss: 1.4876 - val_accuracy: 0.5783\n",
      "Epoch 101/120\n",
      "2625/2625 [==============================] - 0s 157us/step - loss: 0.7251 - accuracy: 0.7474 - val_loss: 1.5048 - val_accuracy: 0.5714\n",
      "Epoch 102/120\n",
      "2625/2625 [==============================] - 0s 132us/step - loss: 0.7243 - accuracy: 0.7520 - val_loss: 1.4054 - val_accuracy: 0.5977\n",
      "Epoch 103/120\n",
      "2625/2625 [==============================] - 0s 125us/step - loss: 0.6859 - accuracy: 0.7570 - val_loss: 1.4606 - val_accuracy: 0.5794\n",
      "Epoch 104/120\n",
      "2625/2625 [==============================] - 0s 130us/step - loss: 0.6955 - accuracy: 0.7501 - val_loss: 1.5126 - val_accuracy: 0.5554\n",
      "Epoch 105/120\n",
      "2625/2625 [==============================] - 0s 142us/step - loss: 0.7134 - accuracy: 0.7490 - val_loss: 1.4986 - val_accuracy: 0.5703\n",
      "Epoch 106/120\n",
      "2625/2625 [==============================] - 0s 139us/step - loss: 0.6675 - accuracy: 0.7707 - val_loss: 1.5246 - val_accuracy: 0.5429\n",
      "Epoch 107/120\n",
      "2625/2625 [==============================] - 0s 145us/step - loss: 0.7666 - accuracy: 0.7310 - val_loss: 1.5603 - val_accuracy: 0.5646\n",
      "Epoch 108/120\n",
      "2625/2625 [==============================] - 0s 153us/step - loss: 0.6890 - accuracy: 0.7642 - val_loss: 1.4892 - val_accuracy: 0.5669\n",
      "Epoch 109/120\n",
      "2625/2625 [==============================] - 0s 162us/step - loss: 0.7560 - accuracy: 0.7383 - val_loss: 1.5163 - val_accuracy: 0.5543\n",
      "Epoch 110/120\n",
      "2625/2625 [==============================] - 0s 159us/step - loss: 0.6929 - accuracy: 0.7581 - val_loss: 1.6625 - val_accuracy: 0.5623\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - 0s 159us/step - loss: 0.7511 - accuracy: 0.7341 - val_loss: 1.4920 - val_accuracy: 0.5543\n",
      "Epoch 112/120\n",
      "2625/2625 [==============================] - 1s 209us/step - loss: 0.7952 - accuracy: 0.7173 - val_loss: 1.5540 - val_accuracy: 0.5623\n",
      "Epoch 113/120\n",
      "2625/2625 [==============================] - 0s 157us/step - loss: 0.7102 - accuracy: 0.7592 - val_loss: 1.5820 - val_accuracy: 0.5554\n",
      "Epoch 114/120\n",
      "2625/2625 [==============================] - 0s 167us/step - loss: 0.7458 - accuracy: 0.7417 - val_loss: 1.5375 - val_accuracy: 0.5566\n",
      "Epoch 115/120\n",
      "2625/2625 [==============================] - 0s 146us/step - loss: 0.7285 - accuracy: 0.7448 - val_loss: 1.5372 - val_accuracy: 0.5771\n",
      "Epoch 116/120\n",
      "2625/2625 [==============================] - 0s 147us/step - loss: 0.6851 - accuracy: 0.7470 - val_loss: 1.6911 - val_accuracy: 0.5680\n",
      "Epoch 117/120\n",
      "2625/2625 [==============================] - 0s 131us/step - loss: 0.7279 - accuracy: 0.7451 - val_loss: 1.5339 - val_accuracy: 0.5520\n",
      "Epoch 118/120\n",
      "2625/2625 [==============================] - 0s 144us/step - loss: 0.6470 - accuracy: 0.7710 - val_loss: 1.6004 - val_accuracy: 0.5600\n",
      "Epoch 119/120\n",
      "2625/2625 [==============================] - 0s 152us/step - loss: 0.7216 - accuracy: 0.7493 - val_loss: 1.5552 - val_accuracy: 0.5760\n",
      "Epoch 120/120\n",
      "2625/2625 [==============================] - 0s 124us/step - loss: 0.6808 - accuracy: 0.7566 - val_loss: 1.6841 - val_accuracy: 0.5771\n",
      "Training finished in 43.14533448219299 seconds\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=num_batch, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=(x_test, y_test), \n",
    "          verbose=1)\n",
    "finish_time = time.time()\n",
    "print(\"Training finished in {} seconds\".format(finish_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9020952582359314\n",
      "Testing Accuracy:  0.5771428346633911\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes spectrogram out of .wav file for prediction\n",
    "#returns different format than get_spectrogram(), usable only in\n",
    "#print_prediction() function\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints prediction in \n",
    "def print_prediction(file_name,model):\n",
    "    prediction_feature = extract_feature(file_name)\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", class_label[predicted_class[0]], '\\n') \n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: right \n",
      "\n",
      "0 \t\t :  0.09295421093702316284179687500000\n",
      "1 \t\t :  0.27327957749366760253906250000000\n",
      "2 \t\t :  0.01250028889626264572143554687500\n",
      "3 \t\t :  0.11387594044208526611328125000000\n",
      "4 \t\t :  0.50309169292449951171875000000000\n",
      "5 \t\t :  0.00311328377574682235717773437500\n",
      "6 \t\t :  0.00118502764962613582611083984375\n"
     ]
    }
   ],
   "source": [
    "print_prediction(test_file_right, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
