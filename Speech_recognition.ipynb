{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.measure import block_reduce\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS\n",
    "image_height = 12\n",
    "image_width = 18\n",
    "input_shape = [image_height, image_width,1]\n",
    "num_labels = 7\n",
    "num_epochs = 20\n",
    "batch_size = 6\n",
    "test_size = 0.2\n",
    "labels = [\"down\",\"go\",\"left\",\"on\",\"right\",\"stop\",\"up\"]\n",
    "PATH = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\"\n",
    "npy_dataset_path = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\\\\npy_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make spectrogram out of wav_file, transform it (reshape,gray,normalize)\n",
    "#and save it as a file.npy\n",
    "def make_spectrogram(wav_file,save_file):\n",
    "    nfft=512\n",
    "    overlap=511\n",
    "    #read file\n",
    "    sr, data = wavfile.read(wav_file)\n",
    "    #make subplot out of it\n",
    "    figure,axes = plt.subplots(1)\n",
    "    figure.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    axes.axis(\"off\")\n",
    "    #make spectrogram\n",
    "    axes.specgram(x=data,Fs=sr,noverlap=overlap,NFFT=nfft)\n",
    "    axes.axis(\"off\")\n",
    "    #change figsize\n",
    "    plt.rcParams[\"figure.figsize\"]=[0.8,0.5]\n",
    "    figure.canvas.draw()\n",
    "    #get size and convert image to RGB byte string\n",
    "    width, height = figure.get_size_inches() * figure.get_dpi()\n",
    "    image = np.frombuffer(figure.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    #reshape\n",
    "    image = np.reshape(image, (int(height), int(width), 3))\n",
    "    plt.close(figure)\n",
    "    #make image gray\n",
    "    gray = np.dot(image[...,:3],[0.299,0.587,0.114])\n",
    "    #normalize image\n",
    "    gray = (gray - gray.min())/(gray.max()-gray.min())\n",
    "    np.save(save_file, gray)\n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spectrogram from npy_file\n",
    "def load_spectrogram(npy_file):\n",
    "    npy_array = np.load(npy_file)\n",
    "    return npy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    #model \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", \n",
    "                    input_shape=input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.adam(), \n",
    "                  loss=keras.losses.categorical_crossentropy, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(npy_dataset, test_size):\n",
    "    train = []\n",
    "    test = []\n",
    "    #split dataset into train and test lists, equally for each label\n",
    "    for label_name in labels:\n",
    "        labeled_list = []\n",
    "        for file_name in os.listdir(npy_dataset):\n",
    "            if label_name in file_name:\n",
    "                labeled_list.append(file_name)\n",
    "        split_index = math.floor(len(labeled_list)*test_size)\n",
    "        test.extend(labeled_list[:split_index])\n",
    "        train.extend(labeled_list[split_index:])\n",
    "    #create x,y train and x,y test in correct size\n",
    "    x_train = np.zeros((len(train), image_height, image_width))\n",
    "    y_train = np.zeros(len(train))\n",
    "    x_test = np.zeros((len(test), image_height, image_width))\n",
    "    y_test = np.zeros(len(test))\n",
    "    \n",
    "    #load spectrograms to x,y train and x,y test\n",
    "    for index, file_name in enumerate(train):\n",
    "        spec = load_spectrogram(npy_dataset+\"\\\\\"+file_name)\n",
    "        if(spec.shape == (image_height, image_width)):\n",
    "            x_train[index, :, :] = spec\n",
    "            y_train[index] = file_name[0]\n",
    "    for index, file_name in enumerate(test):\n",
    "        spec = load_spectrogram(npy_dataset+\"\\\\\"+file_name)\n",
    "        if(spec.shape == (image_height, image_width)):\n",
    "            x_test[index, :, :] = spec\n",
    "            y_test[index] = file_name[0]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, npy_dataset):\n",
    "    #split and reshape dataset\n",
    "    x_train, x_test, y_train, y_test = split_train_test(npy_dataset,test_size)\n",
    "    x_train = x_train.reshape(x_train.shape[0], image_height,\n",
    "                              image_width, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],image_height, \n",
    "                            image_width, 1)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_labels)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_labels)\n",
    "    \n",
    "    #train\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, \n",
    "              epochs=num_epochs, verbose=2, \n",
    "              validation_data=(x_test, y_test))\n",
    "    #save model\n",
    "    file = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json:\n",
    "        json.write(file)\n",
    "    #save weights\n",
    "    model.save_weights(\"weights.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 10, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 14, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               229504    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 249,223\n",
      "Trainable params: 249,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2864 samples, validate on 716 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 1.8950 - accuracy: 0.2252 - val_loss: 1.7321 - val_accuracy: 0.3310\n",
      "Epoch 2/20\n",
      " - 3s - loss: 1.5845 - accuracy: 0.3893 - val_loss: 1.3646 - val_accuracy: 0.5098\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.2688 - accuracy: 0.5244 - val_loss: 1.1138 - val_accuracy: 0.5782\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.0422 - accuracy: 0.6086 - val_loss: 0.9384 - val_accuracy: 0.6341\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.9485 - accuracy: 0.6536 - val_loss: 0.8913 - val_accuracy: 0.6676\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.8399 - accuracy: 0.6903 - val_loss: 0.8160 - val_accuracy: 0.6885\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.7507 - accuracy: 0.7084 - val_loss: 0.8266 - val_accuracy: 0.6955\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.7106 - accuracy: 0.7249 - val_loss: 0.7083 - val_accuracy: 0.7514\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.6651 - accuracy: 0.7510 - val_loss: 0.6786 - val_accuracy: 0.7570\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.6173 - accuracy: 0.7633 - val_loss: 0.7283 - val_accuracy: 0.7430\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.5603 - accuracy: 0.7916 - val_loss: 0.6961 - val_accuracy: 0.7374\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.5300 - accuracy: 0.8073 - val_loss: 0.6568 - val_accuracy: 0.7388\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.4994 - accuracy: 0.8146 - val_loss: 0.6037 - val_accuracy: 0.7975\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.4799 - accuracy: 0.8198 - val_loss: 0.5961 - val_accuracy: 0.7961\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.4356 - accuracy: 0.8334 - val_loss: 0.6157 - val_accuracy: 0.7863\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.4270 - accuracy: 0.8387 - val_loss: 0.5938 - val_accuracy: 0.7807\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.3932 - accuracy: 0.8614 - val_loss: 0.6456 - val_accuracy: 0.7654\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.3687 - accuracy: 0.8659 - val_loss: 0.6128 - val_accuracy: 0.7961\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.3474 - accuracy: 0.8708 - val_loss: 0.5640 - val_accuracy: 0.7989\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.3630 - accuracy: 0.8684 - val_loss: 0.5665 - val_accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model = train_model(model, npy_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
