{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.measure import block_reduce\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS\n",
    "image_height = 12\n",
    "image_width = 18\n",
    "input_shape = [image_height, image_width,1]\n",
    "num_labels = 7\n",
    "num_epochs = 80\n",
    "batch_size = 6\n",
    "test_size = 0.2\n",
    "labels = [\"down\",\"go\",\"left\",\"on\",\"right\",\"stop\",\"up\"]\n",
    "PATH = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\"\n",
    "npy_dataset_path = \"C:\\\\Users\\\\Filip\\\\Desktop\\\\Jupyter\\\\npy_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make spectrogram out of wav_file, transform it (reshape,gray,normalize)\n",
    "#and save it as a file.npy\n",
    "def make_spectrogram(wav_file,save_file):\n",
    "    nfft=512\n",
    "    overlap=511\n",
    "    #read file\n",
    "    sr, data = wavfile.read(wav_file)\n",
    "    #make subplot out of it\n",
    "    figure,axes = plt.subplots(1)\n",
    "    figure.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    axes.axis(\"off\")\n",
    "    #make spectrogram\n",
    "    axes.specgram(x=data,Fs=sr,noverlap=overlap,NFFT=nfft)\n",
    "    axes.axis(\"off\")\n",
    "    #change figsize\n",
    "    plt.rcParams[\"figure.figsize\"]=[0.8,0.5]\n",
    "    figure.canvas.draw()\n",
    "    #get size and convert image to RGB byte string\n",
    "    width, height = figure.get_size_inches() * figure.get_dpi()\n",
    "    image = np.frombuffer(figure.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    #reshape\n",
    "    image = np.reshape(image, (int(height), int(width), 3))\n",
    "    plt.close(figure)\n",
    "    #make image gray\n",
    "    gray = np.dot(image[...,:3],[0.299,0.587,0.114])\n",
    "    #normalize image\n",
    "    gray = (gray - gray.min())/(gray.max()-gray.min())\n",
    "    np.save(save_file, gray)\n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spectrogram from npy_file\n",
    "def load_spectrogram(npy_file):\n",
    "    npy_array = np.load(npy_file)\n",
    "    return npy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    #model \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", \n",
    "                    input_shape=input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.adam(), \n",
    "                  loss=keras.losses.categorical_crossentropy, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(npy_dataset, test_size):\n",
    "    train = []\n",
    "    test = []\n",
    "    #split dataset into train and test lists, equally for each label\n",
    "    for label_name in labels:\n",
    "        labeled_list = []\n",
    "        for file_name in os.listdir(npy_dataset):\n",
    "            if label_name in file_name:\n",
    "                labeled_list.append(file_name)\n",
    "        split_index = math.floor(len(labeled_list)*test_size)\n",
    "        test.extend(labeled_list[:split_index])\n",
    "        train.extend(labeled_list[split_index:])\n",
    "    #create x,y train and x,y test in correct size\n",
    "    x_train = np.zeros((len(train), image_height, image_width))\n",
    "    y_train = np.zeros(len(train))\n",
    "    x_test = np.zeros((len(test), image_height, image_width))\n",
    "    y_test = np.zeros(len(test))\n",
    "    \n",
    "    #load spectrograms to x,y train and x,y test\n",
    "    for index, file_name in enumerate(train):\n",
    "        spec = load_spectrogram(npy_dataset+\"\\\\\"+file_name)\n",
    "        if(spec.shape == (image_height, image_width)):\n",
    "            x_train[index, :, :] = spec\n",
    "            y_train[index] = file_name[0]\n",
    "    for index, file_name in enumerate(test):\n",
    "        spec = load_spectrogram(npy_dataset+\"\\\\\"+file_name)\n",
    "        if(spec.shape == (image_height, image_width)):\n",
    "            x_test[index, :, :] = spec\n",
    "            y_test[index] = file_name[0]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, npy_dataset):\n",
    "    #split and reshape dataset\n",
    "    x_train, x_test, y_train, y_test = split_train_test(npy_dataset,test_size)\n",
    "    x_train = x_train.reshape(x_train.shape[0], image_height,\n",
    "                              image_width, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],image_height, \n",
    "                            image_width, 1)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_labels)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_labels)\n",
    "    \n",
    "    #train\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, \n",
    "              epochs=num_epochs, verbose=2, \n",
    "              validation_data=(x_test, y_test))\n",
    "    #save model\n",
    "    file = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json:\n",
    "        json.write(file)\n",
    "    #save weights\n",
    "    model.save_weights(\"weights.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 10, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 14, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               229504    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 249,223\n",
      "Trainable params: 249,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2864 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      " - 4s - loss: 1.8936 - accuracy: 0.2175 - val_loss: 1.7405 - val_accuracy: 0.2877\n",
      "Epoch 2/80\n",
      " - 4s - loss: 1.5498 - accuracy: 0.4050 - val_loss: 1.2978 - val_accuracy: 0.5098\n",
      "Epoch 3/80\n",
      " - 3s - loss: 1.2208 - accuracy: 0.5443 - val_loss: 1.1313 - val_accuracy: 0.5670\n",
      "Epoch 4/80\n",
      " - 3s - loss: 1.0361 - accuracy: 0.6124 - val_loss: 1.0053 - val_accuracy: 0.6215\n",
      "Epoch 5/80\n",
      " - 3s - loss: 0.9119 - accuracy: 0.6543 - val_loss: 0.8852 - val_accuracy: 0.6732\n",
      "Epoch 6/80\n",
      " - 3s - loss: 0.8363 - accuracy: 0.6872 - val_loss: 0.7832 - val_accuracy: 0.7179\n",
      "Epoch 7/80\n",
      " - 3s - loss: 0.7660 - accuracy: 0.7109 - val_loss: 0.7229 - val_accuracy: 0.7360\n",
      "Epoch 8/80\n",
      " - 3s - loss: 0.7181 - accuracy: 0.7339 - val_loss: 0.7771 - val_accuracy: 0.7025\n",
      "Epoch 9/80\n",
      " - 3s - loss: 0.6705 - accuracy: 0.7535 - val_loss: 0.6685 - val_accuracy: 0.7528\n",
      "Epoch 10/80\n",
      " - 4s - loss: 0.6345 - accuracy: 0.7626 - val_loss: 0.6537 - val_accuracy: 0.7514\n",
      "Epoch 11/80\n",
      " - 4s - loss: 0.5743 - accuracy: 0.7968 - val_loss: 0.6372 - val_accuracy: 0.7626\n",
      "Epoch 12/80\n",
      " - 3s - loss: 0.5773 - accuracy: 0.7888 - val_loss: 0.6665 - val_accuracy: 0.7444\n",
      "Epoch 13/80\n",
      " - 4s - loss: 0.5201 - accuracy: 0.8163 - val_loss: 0.6517 - val_accuracy: 0.7626\n",
      "Epoch 14/80\n",
      " - 3s - loss: 0.4956 - accuracy: 0.8209 - val_loss: 0.6344 - val_accuracy: 0.7682\n",
      "Epoch 15/80\n",
      " - 3s - loss: 0.4752 - accuracy: 0.8244 - val_loss: 0.6446 - val_accuracy: 0.7626\n",
      "Epoch 16/80\n",
      " - 3s - loss: 0.4591 - accuracy: 0.8296 - val_loss: 0.6464 - val_accuracy: 0.7765\n",
      "Epoch 17/80\n",
      " - 3s - loss: 0.4425 - accuracy: 0.8352 - val_loss: 0.5656 - val_accuracy: 0.7891\n",
      "Epoch 18/80\n",
      " - 3s - loss: 0.4057 - accuracy: 0.8464 - val_loss: 0.6271 - val_accuracy: 0.7542\n",
      "Epoch 19/80\n",
      " - 3s - loss: 0.4101 - accuracy: 0.8492 - val_loss: 0.5816 - val_accuracy: 0.7975\n",
      "Epoch 20/80\n",
      " - 3s - loss: 0.3720 - accuracy: 0.8600 - val_loss: 0.7327 - val_accuracy: 0.7514\n",
      "Epoch 21/80\n",
      " - 3s - loss: 0.3753 - accuracy: 0.8663 - val_loss: 0.5967 - val_accuracy: 0.7863\n",
      "Epoch 22/80\n",
      " - 3s - loss: 0.3687 - accuracy: 0.8635 - val_loss: 0.6044 - val_accuracy: 0.7821\n",
      "Epoch 23/80\n",
      " - 3s - loss: 0.3456 - accuracy: 0.8701 - val_loss: 0.5883 - val_accuracy: 0.7947\n",
      "Epoch 24/80\n",
      " - 3s - loss: 0.3310 - accuracy: 0.8767 - val_loss: 0.6410 - val_accuracy: 0.7863\n",
      "Epoch 25/80\n",
      " - 3s - loss: 0.3032 - accuracy: 0.8858 - val_loss: 0.6487 - val_accuracy: 0.7821\n",
      "Epoch 26/80\n",
      " - 3s - loss: 0.3284 - accuracy: 0.8740 - val_loss: 0.6049 - val_accuracy: 0.7975\n",
      "Epoch 27/80\n",
      " - 3s - loss: 0.2955 - accuracy: 0.8932 - val_loss: 0.5801 - val_accuracy: 0.8003\n",
      "Epoch 28/80\n",
      " - 3s - loss: 0.2876 - accuracy: 0.8994 - val_loss: 0.6268 - val_accuracy: 0.7807\n",
      "Epoch 29/80\n",
      " - 3s - loss: 0.2739 - accuracy: 0.8946 - val_loss: 0.6384 - val_accuracy: 0.7849\n",
      "Epoch 30/80\n",
      " - 3s - loss: 0.2737 - accuracy: 0.8949 - val_loss: 0.5719 - val_accuracy: 0.8087\n",
      "Epoch 31/80\n",
      " - 3s - loss: 0.2479 - accuracy: 0.9078 - val_loss: 0.6144 - val_accuracy: 0.7961\n",
      "Epoch 32/80\n",
      " - 3s - loss: 0.2585 - accuracy: 0.9120 - val_loss: 0.6550 - val_accuracy: 0.8003\n",
      "Epoch 33/80\n",
      " - 3s - loss: 0.2326 - accuracy: 0.9138 - val_loss: 0.6724 - val_accuracy: 0.7807\n",
      "Epoch 34/80\n",
      " - 3s - loss: 0.2384 - accuracy: 0.9148 - val_loss: 0.6498 - val_accuracy: 0.7989\n",
      "Epoch 35/80\n",
      " - 3s - loss: 0.2324 - accuracy: 0.9176 - val_loss: 0.6788 - val_accuracy: 0.7891\n",
      "Epoch 36/80\n",
      " - 3s - loss: 0.2201 - accuracy: 0.9190 - val_loss: 0.6830 - val_accuracy: 0.8017\n",
      "Epoch 37/80\n",
      " - 3s - loss: 0.2410 - accuracy: 0.9110 - val_loss: 0.6726 - val_accuracy: 0.8017\n",
      "Epoch 38/80\n",
      " - 3s - loss: 0.2093 - accuracy: 0.9246 - val_loss: 0.6533 - val_accuracy: 0.7919\n",
      "Epoch 39/80\n",
      " - 3s - loss: 0.2011 - accuracy: 0.9249 - val_loss: 0.7347 - val_accuracy: 0.7863\n",
      "Epoch 40/80\n",
      " - 3s - loss: 0.2155 - accuracy: 0.9242 - val_loss: 0.6985 - val_accuracy: 0.7919\n",
      "Epoch 41/80\n",
      " - 3s - loss: 0.1978 - accuracy: 0.9312 - val_loss: 0.6698 - val_accuracy: 0.8101\n",
      "Epoch 42/80\n",
      " - 3s - loss: 0.1840 - accuracy: 0.9309 - val_loss: 0.7295 - val_accuracy: 0.7933\n",
      "Epoch 43/80\n",
      " - 3s - loss: 0.1909 - accuracy: 0.9323 - val_loss: 0.8096 - val_accuracy: 0.7919\n",
      "Epoch 44/80\n",
      " - 3s - loss: 0.1797 - accuracy: 0.9358 - val_loss: 0.7479 - val_accuracy: 0.7793\n",
      "Epoch 45/80\n",
      " - 3s - loss: 0.1808 - accuracy: 0.9358 - val_loss: 0.7620 - val_accuracy: 0.7961\n",
      "Epoch 46/80\n",
      " - 3s - loss: 0.1876 - accuracy: 0.9372 - val_loss: 0.7062 - val_accuracy: 0.8045\n",
      "Epoch 47/80\n",
      " - 3s - loss: 0.1772 - accuracy: 0.9410 - val_loss: 0.9097 - val_accuracy: 0.7668\n",
      "Epoch 48/80\n",
      " - 3s - loss: 0.1792 - accuracy: 0.9378 - val_loss: 0.7048 - val_accuracy: 0.8170\n",
      "Epoch 49/80\n",
      " - 3s - loss: 0.1502 - accuracy: 0.9476 - val_loss: 0.8670 - val_accuracy: 0.7877\n",
      "Epoch 50/80\n",
      " - 3s - loss: 0.1627 - accuracy: 0.9413 - val_loss: 0.9093 - val_accuracy: 0.7919\n",
      "Epoch 51/80\n",
      " - 3s - loss: 0.1574 - accuracy: 0.9431 - val_loss: 0.9094 - val_accuracy: 0.7877\n",
      "Epoch 52/80\n",
      " - 3s - loss: 0.1499 - accuracy: 0.9462 - val_loss: 0.8356 - val_accuracy: 0.7863\n",
      "Epoch 53/80\n",
      " - 3s - loss: 0.1608 - accuracy: 0.9427 - val_loss: 0.8833 - val_accuracy: 0.7807\n",
      "Epoch 54/80\n",
      " - 3s - loss: 0.1563 - accuracy: 0.9462 - val_loss: 0.7733 - val_accuracy: 0.8101\n",
      "Epoch 55/80\n",
      " - 3s - loss: 0.1539 - accuracy: 0.9490 - val_loss: 0.8633 - val_accuracy: 0.8017\n",
      "Epoch 56/80\n",
      " - 3s - loss: 0.1678 - accuracy: 0.9466 - val_loss: 0.7940 - val_accuracy: 0.7891\n",
      "Epoch 57/80\n",
      " - 3s - loss: 0.1483 - accuracy: 0.9511 - val_loss: 0.7983 - val_accuracy: 0.8115\n",
      "Epoch 58/80\n",
      " - 3s - loss: 0.1425 - accuracy: 0.9462 - val_loss: 0.7901 - val_accuracy: 0.8073\n",
      "Epoch 59/80\n",
      " - 3s - loss: 0.1297 - accuracy: 0.9543 - val_loss: 0.8255 - val_accuracy: 0.7961\n",
      "Epoch 60/80\n",
      " - 3s - loss: 0.1255 - accuracy: 0.9605 - val_loss: 0.9121 - val_accuracy: 0.8031\n",
      "Epoch 61/80\n",
      " - 3s - loss: 0.1315 - accuracy: 0.9553 - val_loss: 0.9671 - val_accuracy: 0.7835\n",
      "Epoch 62/80\n",
      " - 3s - loss: 0.1260 - accuracy: 0.9543 - val_loss: 1.1690 - val_accuracy: 0.7821\n",
      "Epoch 63/80\n",
      " - 3s - loss: 0.1591 - accuracy: 0.9487 - val_loss: 0.9643 - val_accuracy: 0.7975\n",
      "Epoch 64/80\n",
      " - 3s - loss: 0.1327 - accuracy: 0.9584 - val_loss: 0.9408 - val_accuracy: 0.7961\n",
      "Epoch 65/80\n",
      " - 3s - loss: 0.1174 - accuracy: 0.9609 - val_loss: 0.9682 - val_accuracy: 0.7877\n",
      "Epoch 66/80\n",
      " - 3s - loss: 0.1344 - accuracy: 0.9567 - val_loss: 0.8605 - val_accuracy: 0.7961\n",
      "Epoch 67/80\n",
      " - 3s - loss: 0.1099 - accuracy: 0.9658 - val_loss: 0.9361 - val_accuracy: 0.7807\n",
      "Epoch 68/80\n",
      " - 3s - loss: 0.1366 - accuracy: 0.9550 - val_loss: 0.7883 - val_accuracy: 0.7961\n",
      "Epoch 69/80\n",
      " - 3s - loss: 0.1386 - accuracy: 0.9490 - val_loss: 0.9662 - val_accuracy: 0.7598\n",
      "Epoch 70/80\n",
      " - 3s - loss: 0.1279 - accuracy: 0.9571 - val_loss: 0.9058 - val_accuracy: 0.8003\n",
      "Epoch 71/80\n",
      " - 3s - loss: 0.1242 - accuracy: 0.9574 - val_loss: 0.9485 - val_accuracy: 0.7668\n",
      "Epoch 72/80\n",
      " - 3s - loss: 0.1270 - accuracy: 0.9546 - val_loss: 0.8681 - val_accuracy: 0.7849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/80\n",
      " - 3s - loss: 0.1318 - accuracy: 0.9546 - val_loss: 0.8089 - val_accuracy: 0.7947\n",
      "Epoch 74/80\n",
      " - 3s - loss: 0.1141 - accuracy: 0.9602 - val_loss: 0.8956 - val_accuracy: 0.7877\n",
      "Epoch 75/80\n",
      " - 3s - loss: 0.1229 - accuracy: 0.9574 - val_loss: 0.7922 - val_accuracy: 0.8003\n",
      "Epoch 76/80\n",
      " - 3s - loss: 0.1163 - accuracy: 0.9588 - val_loss: 0.9029 - val_accuracy: 0.7989\n",
      "Epoch 77/80\n",
      " - 3s - loss: 0.1219 - accuracy: 0.9567 - val_loss: 0.8964 - val_accuracy: 0.7947\n",
      "Epoch 78/80\n",
      " - 3s - loss: 0.1103 - accuracy: 0.9595 - val_loss: 0.9413 - val_accuracy: 0.7835\n",
      "Epoch 79/80\n",
      " - 3s - loss: 0.1094 - accuracy: 0.9626 - val_loss: 0.8761 - val_accuracy: 0.8017\n",
      "Epoch 80/80\n",
      " - 3s - loss: 0.1184 - accuracy: 0.9637 - val_loss: 0.9442 - val_accuracy: 0.7821\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model = train_model(model, npy_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
